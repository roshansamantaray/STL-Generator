{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e2a9a84-ec39-4ecf-a3fb-de0d6a63bf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\rosha\\anaconda3\\lib\\site-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rosha\\anaconda3\\lib\\site-packages (from openai==0.28) (4.66.5)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\rosha\\anaconda3\\lib\\site-packages (from openai==0.28) (3.10.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rosha\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rosha\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rosha\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rosha\\anaconda3\\lib\\site-packages (from requests>=2.20->openai==0.28) (2024.12.14)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rosha\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rosha\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rosha\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rosha\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rosha\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\rosha\\anaconda3\\lib\\site-packages (from aiohttp->openai==0.28) (1.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rosha\\anaconda3\\lib\\site-packages (from tqdm->openai==0.28) (0.4.6)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.59.6\n",
      "    Uninstalling openai-1.59.6:\n",
      "      Successfully uninstalled openai-1.59.6\n",
      "Successfully installed openai-0.28.0\n",
      "Collecting numpy-stl\n",
      "  Downloading numpy_stl-3.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\rosha\\anaconda3\\lib\\site-packages (from numpy-stl) (1.26.4)\n",
      "Collecting python-utils>=3.4.5 (from numpy-stl)\n",
      "  Downloading python_utils-3.9.1-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: typing_extensions>3.10.0.2 in c:\\users\\rosha\\anaconda3\\lib\\site-packages (from python-utils>=3.4.5->numpy-stl) (4.11.0)\n",
      "Downloading numpy_stl-3.2.0-py3-none-any.whl (20 kB)\n",
      "Downloading python_utils-3.9.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: python-utils, numpy-stl\n",
      "Successfully installed numpy-stl-3.2.0 python-utils-3.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28\n",
    "!pip install numpy-stl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca404cc4-db71-4164-b7bb-607483acaca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a prompt:  Design a cylindrical water tank with the following specifications: a diameter of 2.5 meters, a height of 4 meters, and a capacity of 20,000 liters. The material should be stainless steel, and the tank should include an outlet valve at the bottom and a ladder attached to the side. Provide details for the base thickness (5 mm) and wall thickness (3 mm). Specify all dimensions and features in the output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"object\": \"cylindrical_water_tank\",\n",
      "    \"dimensions\": {\n",
      "        \"diameter\": 2.5,\n",
      "        \"height\": 4\n",
      "    },\n",
      "    \"capacity_liters\": 20000,\n",
      "    \"material\": \"stainless_steel\",\n",
      "    \"features\": {\n",
      "        \"outlet_valve\": {\n",
      "            \"position\": \"bottom\"\n",
      "        },\n",
      "        \"ladder\": {\n",
      "            \"position\": \"side\"\n",
      "        },\n",
      "        \"base_thickness_mm\": 5,\n",
      "        \"wall_thickness_mm\": 3\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Replace with your Azure details\n",
    "endpoint = \"https://pgazureaideplo6829607801.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-08-01-preview\"\n",
    "api_key = \"f8285b2a596f41cb8b3f36ddb0b2c31a\"\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"api-key\": api_key\n",
    "}\n",
    "\n",
    "def is_valid_3d_object_prompt(user_prompt):\n",
    "    system_instruction = (\n",
    "        \"You are an intelligent assistant. Your task is to determine whether the given prompt is specifically \"\n",
    "        \"intended for creating a 3D object. Valid prompts should describe a 3D object to be created, including \"\n",
    "        \"specific attributes such as dimensions, shapes, or material properties. Return 'Valid' if the prompt \"\n",
    "        \"is for creating a 3D object, and 'Invalid' otherwise.\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            endpoint,\n",
    "            headers=headers,\n",
    "            json={\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": system_instruction},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                \"max_tokens\": 10\n",
    "            }\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()[\"choices\"][0][\"message\"][\"content\"].strip().lower()\n",
    "            return result == 'valid'\n",
    "        else:\n",
    "            print(f\"Error! Status Code: {response.status_code}\")\n",
    "            print(response.json())\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error during validation: {e}\")\n",
    "        return False\n",
    "\n",
    "def extract_features(user_prompt):\n",
    "    if not is_valid_3d_object_prompt(user_prompt):\n",
    "        return {\"error\": \"The prompt is not a valid prompt for creating a 3D object.\"}\n",
    "\n",
    "    system_instruction = (\n",
    "        \"You are an intelligent assistant. Your task is to extract all the necessary features, \"\n",
    "        \"key dimensions, and attributes for creating a 3D object from the given user prompt and \"\n",
    "        \"return the results in structured JSON format. Ensure the JSON is well-formed and human-readable.\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            endpoint,\n",
    "            headers=headers,\n",
    "            json={\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": system_instruction},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                \"max_tokens\": 1000\n",
    "            }\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            raw_content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "            # Remove backticks and extract the JSON part\n",
    "            clean_content = raw_content.strip(\"```\").strip()\n",
    "            if clean_content.startswith(\"json\"):\n",
    "                clean_content = clean_content[4:].strip()\n",
    "            return json.loads(clean_content)\n",
    "        else:\n",
    "            print(f\"Error! Status Code: {response.status_code}\")\n",
    "            print(\"Response Content:\", response.text)\n",
    "            return {\"error\": \"Failed to process the prompt.\"}\n",
    "    except json.JSONDecodeError as json_err:\n",
    "        print(f\"JSON decode error: {json_err}\")\n",
    "        print(\"Response Content:\", response.text)\n",
    "        return {\"error\": \"Response is not in valid JSON format.\"}\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return {\"error\": \"An unexpected error occurred.\"}\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    user_prompt = input(\"Enter a prompt: \")\n",
    "    features_json = extract_features(user_prompt)\n",
    "\n",
    "    if \"error\" in features_json:\n",
    "        print(features_json[\"error\"])\n",
    "    else:\n",
    "        print(json.dumps(features_json, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b0d0f0-13f0-4088-9126-773d553baebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
